\chapter{Fundamental data concepts}
\label{chap:data}

\chapterprecishere{The simple believes everything,
  \par\raggedleft but the prudent gives thought to his steps.
  \par\raggedleft--- \textup{Proverbs 14:15} (ESV)}

% \begin{itemize}
%   \item Variables, types etc
%   \item Records
%   \item Tidy data
% \end{itemize}

A useful start point for someone studying data science is the definition of the term
itself.

\begin{mainbox}{Chapter remarks}
  \boxsubtitle{Context}

  \begin{itemize}
    \item \dots
  \end{itemize}

  \boxsubtitle{Objectives}

  \begin{itemize}
    \item Understand the definition of data science.
    \item Understand the main types of data.
  \end{itemize}

  \boxsubtitle{Takeways}

  \begin{itemize}
    \item Data science is a new science.
    \item Data science is the study of computational methods to extract knowledge from
      measurable phenomena.
  \end{itemize}
\end{mainbox}

For \textcite{Zumel2019}, \emph{``data science is a cross-disciplinary practice that draws
on methods from data engineering, descriptive statistics, data mining, machine learning,
and predictive analytics.''}  They compare the area with the operations research, stating
that data science focuses on implementing data-driven decisions and managing their
consequences.

\begin{mainbox}{Zumel and Mount's definition}
  \begin{itemize}
    \item Cross-disciplinary practice that draws on methods from data
    engineering, descriptive statistics, data mining, machine learning, and predictive
    analytics.
    \item Focuses on implementing data-driven decisions and managing their consequences.
  \end{itemize}
\end{mainbox}

\textcite{Hickham2023} state that \emph{``data science is an exciting discipline that
allows you to transform raw data into understanding, insight, and knowledge.''}

\begin{mainbox}{Hickham's definition}
  \begin{itemize}
    \item Transform raw data into understanding, insight, and knowledge.
    \item Not necessarily a definition.
  \end{itemize}
\end{mainbox}

I find the first definition too restrictive once new methods and techniques are always
under development.  We never know when new ``data-related'' methods will become obsolete
or a trend.  Also, \textcite{Zumel2019}'s view gives the impression that data science is a
operations research subfield.  Although I will not try to prove otherwise, I think it will
be much more useful to see it as an independent field of study.  Obviously, there will be
many intersections between both areas (and many other areas as well.)  Because of such
intersections, I will try my best to keep definitions and
terms standardized throughout chapters, sometimes avoiding popular terms that may generate
ambiguities or confusion.

The second one is not really a definition.  However, it states clearly \emph{what} data
science enables us to do.  From these thoughts, let's define the term.

\begin{displayquote}
  \em
  Data science is the study of computational methods to extract knowledge from
  measurable phenomena.
\end{displayquote}

I want to highlight the meaning of some terms in this definition.  \emph{Computational methods} means
that data science methods use computers to handle data and perform the calculations.
\emph{Knowledge} means information that humans can easily understand or apply to solve
problems.  \emph{Measurable phenomena} are events or processes where raw data can be
quantified in some way.  \emph{Raw data} are data collected directly from some source and
that have not been subject to any other manipulation by a software program or a human
expert.  \emph{Data} is any piece of information that can be digitally stored.

\begin{mainbox}{My definition}
  \begin{itemize}
    \item Data science is the study of computational methods to extract knowledge from
      measurable phenomena.
    \item Computational methods use computers to handle data and perform the calculations.
    \item Knowledge is information that humans can easily understand or apply to solve
      problems.
    \item Measurable phenomena are events or processes where raw data can be quantified
      in some way.
    \item Raw data are data collected directly from some source and that have not been
      subject to any other manipulation by a software program or a human expert.
    \item Data is any piece of information that can be digitally stored.
  \end{itemize}
\end{mainbox}

\textcite{Kelleher2018} summarize very well the challenges data science takes up:
``extracting non-obvious and useful patterns from large data sets [\dots]; capturing,
cleaning, and transforming [\dots] data; [storing and processing] big [\dots] data sets;
and questions related to data ethics and regulation.''

\begin{mainbox}{Kelleher and Tierney's challenges}
  \begin{itemize}
    \item Extracting non-obvious and useful patterns from large data sets.
    \item Capturing, cleaning, and transforming data.
    \item Storing and processing big data sets.
    \item Questions related to data ethics and regulation.
  \end{itemize}
\end{mainbox}

Data science contrasts with conventional sciences.  Usually, a ``science'' is named after
its object of study.  Biology is the study of the life, Earth science studies the planet
Earth, and so on.  I argue that data science does not study data itself, but how we can
``listen'' them to understand a phenomenon.  The conventional scientific paradigm is
essentially model-driven: we observe a phenomenon related to the object of study, we
reason the possible explanation (the model or hypothesis,) and we validate our hypothesis
(most of the time using data, though.)  In data science, however, we extract the knowledge
directly and primarily from the data.  The expert knowledge and reasoning may be taken
into account, but we give data the opportunity to surprise us.  Thus, the objects of the
study in data science are the computational methods and processes that can extract
reliable and ethical knowledge from huge amounts of data.

\def\verrids{(0,0) circle (20mm)}
\def\verrist{(-2.5,0) circle (15mm)}
\def\verride {(2.5,0) circle (15mm)}
\def\verrics {(0,-2.5) circle (15mm)}

\begin{figure}
  \centering
  \begin{tikzpicture}
    \begin{scope}
      \clip \verrids;
      \fill[filled] \verrist;
      \fill[filled] \verride;
      \fill[filled] \verrics;
    \end{scope}
    \draw[outline] \verrids node(ds) {};
    \draw[outline] \verrist node {statistics};
    \draw[outline, text width=27mm, text centered] \verride node {domain expertise philosophy};
    \draw[outline] \verrics node {computer science};
    \node[anchor=north,above] at (0, 1) {data science};
  \end{tikzpicture}
  \caption{
    My view of data science.  Data science is an entire new science.  Being a new science
    does not mean that its basis is built from the ground up.  Most of the subjects in
    data science come from other sciences, but its object of study (computational methods
    to extract knowledge from measurable phenomena) is particular enough to unfold
    new scientific questions -- such as data ethics, data collection, etc.
  }
\end{figure}

\begin{mainbox}{Data science vs conventional sciences}
  \begin{itemize}
    \item Conventional sciences are model-driven: observation, hypothesis, and validation.
    \item In data science, we extract the knowledge directly and primarily from the data.
    \item Data science studies the computational methods and processes that can extract
      reliable and ethical knowledge from huge amounts of data.
  \end{itemize}
\end{mainbox}

\section{Deepening into the definition}

As expected, data science is not a isolated science.  It incorporates several concepts
from other fields and sciences.  In this section, I explain the basis of each component in
the provided definition.

\subsection{Phenomena}

Phenomenon is a term used to describe any observable event or process.  They are the
source we use to understand the world around us.  In general, we use our senses to
perceive phenomena.  To make sense of them, we use our knowledge and reasoning.

Philosophy is the study of knowledge and reasoning.  It is a very broad field of study
that has been divided into many subfields.  One of them is epistemology, which is the
study of knowledge.  Epistemology is the field of philosophy that studies how we can
acquire knowledge and how we can distinguish between knowledge and opinion.  In
particular, epistemology studies the nature of knowledge, justification, and the
rationality of belief.

Another important subfield in philosophy is ontology, which is the study of being.  It
studies the nature of being, existence, or reality.  Ontology is the field of philosophy
that studies what exists and how we can classify it.  In particular, ontology studies the
nature of categories, properties, and relations.

Finally, logic is the study of reasoning.  It studies the nature of reasoning and
argumentation.  In particular, logic studies the nature of inference, validity, and
fallacies.

\begin{mainbox}{Philosophy}
  \begin{itemize}
    \item Epistemology: the study of knowledge.
    \item Ontology: the study of being.
    \item Logic: the study of reasoning.
  \end{itemize}
\end{mainbox}

In the context of data science, we usually focus on phenomena from particular domain of
expertise.  For example, we may be interested in the phenomena related to the stock
market, the phenomena related to the weather, or the phenomena related to the human
health.  Thus, we need to understand the nature of the phenomena we are studying.

Thus, fully understading the phenomena we are tackling requires both a general knowledge
of epistemology, ontology, and logic, and a particular knowledge of the domain of
expertise.

Observe as well that we do not restrict ourselves to the ``qualitative'' understanding of
philosophy.  There are several computational methods that implements the concepts of
epistemology, ontology, and logic.  For example, we can use a computer to perform
deductive reasoning, to classify objects, or to validate an argument.  Also, we have
strong mathematical foundations and computational tools to organize categories, relations, and
properties.

The reason we need to understand the nature of the phenomena we are studying is that we
need to guarantee that the data we are collecting are relevant to the problem we are
trying to solve.  Incorrectly perception of the phenomena may lead to incorrect data
collection, which may lead to incorrect conclusions.

\begin{mainbox}{Phenomena}
  \begin{itemize}
    \item Phenomena are the source we use to understand the world around us.
    \item We use our senses to perceive phenomena.
    \item We use our knowledge and reasoning to make sense of them.
    \item Computational methods can be used to implement knowledge and reasoning.
    \item Phenomena are the source of data.
    \item We need to understand the nature of the phenomena we are studying.
    \item Incorrectly perception of the phenomena may lead to incorrect data collection,
      which may lead to incorrect conclusions.
  \end{itemize}
\end{mainbox}

\subsection{Measuments}

In data science, we are interested in measurable phenomena.  Measurable phenomena are
those that we can quantify in some way.  For example, the temperature of a room is a
measurable phenomenon because we can measure it using a thermometer.  The number of
people in a room is also a measurable phenomenon because we can count them.

When we quantify a phenomenon, we perform data collection.  Data collection is the process
of gathering data on targeted phenomenon in an established systematic way.
Once we have collected the data, we need to store them.  Data storage is the process of
storing data in a computer.

To perform those tasks, we need to understand the nature of data.  Data are any piece of
information that can be digitally stored.  Data can be stored in many different formats.
For example, we can store data in a spreadsheet, in a database, or in a text file.  We can
also store data in many different types.  For example, we can store data as numbers,
strings, or dates.

In data science, studying data types is important because they need to correctly reflect
the nature of the source phenomenon and be compatible with the computational methods we
are using.  Data types also restrict the operations we can perform on the data.

The foundation and tools to understand data types come from computer science.  Among the
subfields, I highlight:
\begin{itemize}
  \item Algorithms and data structures: the study of data types and the computational
    methods to manipulate them.
  \item Databases: the study of storing and retrieving data.
\end{itemize}

\begin{mainbox}{Measurable phenomena}
  \begin{itemize}
    \item Measurable phenomena are those that we can quantify in some way.
    \item Data collection is the process of gathering data on targeted phenomenon in an
      established systematic way.
    \item Data storage is the process of storing data in a computer.
    \item Data are any piece of information that can be digitally stored.
    \item Data can be stored in many different formats.
    \item Data can be stored in many different types.
    \item Data types need to correctly reflect the nature of the source phenomenon and be
      compatible with the computational methods we are using.
    \item Algorithms, data structures, and databases are important subfields of computer
      science when studying data collection, data storage, and data types.
  \end{itemize}
\end{mainbox}

\subsection{Knowledge extraction}

Once we have collected and stored the data, we need to extract knowledge from them.  In
data science, we use computational methods to extract knowledge from data.  These
computational methods may come from many different fields.  In particular, I highlight:
\begin{itemize}
  \item Statistics: the study of data collection, organization, analysis, interpretation,
    and presentation.
  \item Machine learning: the study of computational methods that can automatically learn from data.
  \item Artificial intelligence: the study of computational methods that can mimic human
    intelligence.
\end{itemize}

Also, many other fields contribute to the development of domain-specific computational
methods to extract knowledge from data.  For example, in the field of biology, we have
bioinformatics, which is the study of computational methods to analyze biological data.
Earth sciences have geoinformatics, which is the study of computational methods to
analyze geographical data.  And so on.

Each method has its own assumptions and limitations.  Thus, we need to understand the
nature of the methods we are using.  In particular, we need to understand the
expected input and output of them.  Whenever the available data do not match the
requirements of the method, we may perform data manipulation\footnote{%
  It is important to highlight that it is expected that some of the methods assumptions
  are not fully met.  These methods are usually robust enough to extract valuable
  knowledge even when data contain imperfections, errors and noise.  However, it is still
  useful to perform data manipulation to adjust data as much as possible.%
}.

Data manipulation mainly includes data cleaning, data transformation, and data
integration. Data cleaning is the process of detecting and correcting (or removing)
corrupt or inaccurate pieces of data.  Data transformation is the process of converting
data from one format or type to another.  Data integration is the process of combining
data from different sources into a single, unified view.

\begin{mainbox}{Knowledge extraction}
  \begin{itemize}
    \item We use computational methods to extract knowledge from data.
    \item Statistics, machine learning, and artificial intelligence are important
      sciences when studying knowledge extraction.
    \item Computational methods always have their own assumptions and limitations.
    \item Data manipulation is the process of adjusting data to the requirements of the
      computational methods.
    \item Data cleaning is the process of detecting and correcting (or removing) corrupt
      or inaccurate pieces of data.
    \item Data transformation is the process of converting data from one format or type
      to another.
    \item Data integration is the process of combining data from different sources into
      a single, unified view.
  \end{itemize}
\end{mainbox}

\section{Structured data}

As one expects, when we measure a phenomenon, the resulting data come in many different
formats. Examples\dots

Thus, it is important to
